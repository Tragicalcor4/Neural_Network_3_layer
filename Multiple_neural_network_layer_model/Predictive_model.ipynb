{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "import cupy as cp\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10, 10))\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        img_2d = image.reshape((28, 28))  # Reshape image to 2D matrix\n",
    "        axes[i].imshow(img_2d, cmap='gray')\n",
    "        axes[i].set_title(label)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data_dir = r'C:\\Users\\ebi19\\OneDrive\\Documents\\Jypyter_apps\\Neural_Network_3_layer\\Multiple_neural_network_layer_model\\Lions and Cheetahs'\n",
    "    classes = ['Lions', 'Cheetahs']\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    test_split = 0.2\n",
    "    for index, label in enumerate(classes):\n",
    "        path = os.path.join(data_dir, label)\n",
    "        files = os.listdir(path)\n",
    "        for i, file in enumerate(files):\n",
    "            image_path = os.path.join(path, file)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.resize((64, 64))\n",
    "            image = cp.asarray(image, dtype=cp.float32) / 255.\n",
    "            if i < int(len(files) * (1 - test_split)):\n",
    "                X_train.append(cp.ndarray.flatten(image))\n",
    "                y_train.append(index)\n",
    "            else:\n",
    "                X_test.append(cp.ndarray.flatten(image))\n",
    "                y_test.append(index)\n",
    "    X_train = cp.vstack(X_train)\n",
    "    X_train = X_train.T\n",
    "    X_test = cp.vstack(X_test)\n",
    "    X_test = X_test.T\n",
    "    y_train = cp.asarray(y_train, dtype=cp.int32)\n",
    "    y_test = cp.asarray(y_test, dtype=cp.int32)\n",
    "    y_test = y_test.reshape(y_test.shape[-1],1).T\n",
    "    y_train = y_train.reshape(y_train.shape[-1],1).T\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_size(X,Y):\n",
    "    \n",
    "    n_x = cp.shape(X)\n",
    "    n_x = n_x[0]\n",
    "    n_h = 2500 # size of hidden layer 1\n",
    "    n_z = 1250 # size of hidden layer 2\n",
    "    n_y = cp.shape(Y)\n",
    "    n_y = n_y[0]\n",
    "\n",
    "    return n_x,n_h,n_z,n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relu(x):\n",
    "    return cp.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each row of x.\"\"\"\n",
    "    e_x = cp.exp(x - cp.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_z,n_y):\n",
    "\n",
    "    w1 = cp.random.randn(n_h,n_x) * 0.001\n",
    "    b1 = cp.zeros((n_h , 1))\n",
    "    w2 = cp.random.randn(n_z,n_h) * 0.001\n",
    "    b2 = cp.zeros((n_z,1))\n",
    "    w3 = cp.random.randn(n_y,n_z) * 0.001\n",
    "    b3 = cp.zeros((n_y,1))\n",
    "\n",
    "    parameters = { \"w1\" : w1 , \"b1\" : b1 , \"w2\" : w2, \"b2\" : b2, \"w3\" : w3, \"b3\" : b3}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,parameters):\n",
    "\n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    \n",
    "    z1 = cp.dot(w1,X) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = cp.dot(w2,a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = cp.dot(w3,a2) + b3\n",
    "    a3 = relu(z3)\n",
    "\n",
    "    caches = {\"z1\" : z1, \"a1\" : a1, \"z2\": z2, \"a2\" : a2, \"z3\" : z3, \"a3\" : a3}\n",
    "\n",
    "    return a3,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(a3, Y,parameters):\n",
    "    m = Y.shape[0]\n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    epsilon = 1e-7\n",
    "    cost = -1/m * cp.sum(Y*cp.log(a3+epsilon) + (1-Y)*cp.log(1-a3+epsilon)) \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(parameters,caches,X,Y):\n",
    "\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    a1 = caches[\"a1\"]\n",
    "    a2 = caches[\"a2\"]\n",
    "    a3 = caches[\"a3\"]\n",
    "    z1 = caches[\"z1\"]\n",
    "    z2 = caches[\"z2\"]\n",
    "    z3 = caches[\"z3\"]\n",
    "\n",
    "    dz3  = a3 - Y\n",
    "    dw3 = cp.dot(dz3,a2.T)/m \n",
    "    db3 = cp.sum(dz3,axis = 1, keepdims=True)/m\n",
    "    da2 = cp.dot(w3.T,dz3)\n",
    "    dz2 = cp.multiply(da2,a2)\n",
    "    dw2 = cp.dot(dz2,a1.T)/m \n",
    "    db2 = cp.sum(dz2,axis = 1, keepdims=True)/m\n",
    "    da1 = cp.dot(w2.T,dz2)\n",
    "    dz1 = cp.multiply(da1,a1)\n",
    "    dw1 = cp.dot(dz1,X.T)/m \n",
    "    db1 = cp.sum(dz1, axis=1, keepdims= True)/m\n",
    "\n",
    "    backprop = { \"dz3\" : dz3, \"dw3\" : dw3, \"db3\" : db3, \"da2\" : da2, \"dz2\" : dz2, \"dw2\" : dw2, \"db2\" : db2, \"da1\" : da1, \"dz1\" : dz1, \"dw1\" : dw1, \"db1\" : db1}\n",
    "    return backprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(backprop, learning_rate ,parameters):\n",
    "\n",
    "    w1 = copy.deepcopy(parameters[\"w1\"])\n",
    "    w2 = copy.deepcopy(parameters[\"w2\"])\n",
    "    w3 = copy.deepcopy(parameters[\"w3\"])\n",
    "    b1 = copy.deepcopy(parameters[\"b1\"])\n",
    "    b2 = copy.deepcopy(parameters[\"b2\"])\n",
    "    b3 = copy.deepcopy(parameters[\"b3\"])\n",
    "\n",
    "    dw1 = backprop[\"dw1\"]\n",
    "    dw2 = backprop[\"dw2\"]\n",
    "    dw3 = backprop[\"dw3\"]\n",
    "    db1 = backprop[\"db1\"]\n",
    "    db2 = backprop[\"db2\"]\n",
    "    db3 = backprop[\"db3\"]\n",
    "\n",
    "    #updating the parameters\n",
    "\n",
    "    w1 = w1 - (learning_rate * dw1)\n",
    "    w2 = w2 - (learning_rate * dw2)\n",
    "    w3 = w3 - (learning_rate * dw3)\n",
    "\n",
    "    b1 = b1 - (learning_rate * db1)\n",
    "    b2 = b2 - (learning_rate * db2)\n",
    "    b3 = b3 - (learning_rate * db3)\n",
    "\n",
    "    #storing updated parameters in the dictionary\n",
    "\n",
    "    parameters = {\"w1\" : w1, \"w2\": w2, \"w3\" : w3, \"b1\" : b1, \"b2\" : b2, \"b3\" : b3}\n",
    "\n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,iterations,learning_rate):\n",
    "\n",
    "    n_x,n_h,n_z,n_y = layer_size(X,Y)\n",
    "    parameters = initialize_parameters(n_x,n_h,n_z,n_y)\n",
    "\n",
    "    for i in range(0,iterations):\n",
    "        a3,caches = forward_prop(X,parameters)\n",
    "        cost = cost_function(a3,Y,parameters)\n",
    "        backprop = backward_prop(parameters,caches,X,Y)\n",
    "        parameters = update_parameters(backprop, learning_rate ,parameters)\n",
    "\n",
    "        #print(\"updated parameters = \",parameters)\n",
    "        if i % 100 == 0:\n",
    "           print(f\"Cost after iteration {i}: {cost}\")\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    # Implement forward propagation to get predictions\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    A, _ = forward_prop(X, parameters)\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "    return Y_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop_test(X,parameters):\n",
    "\n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    b3 = b3[:,:10000] #depends on the shape of Y_test\n",
    "    \n",
    "    \n",
    "    z1 = cp.dot(w1,X) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = cp.dot(w2,a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = cp.dot(w3,a2) + b3\n",
    "    a3 = relu(z3)\n",
    "\n",
    "    caches = {\"z1\" : z1, \"a1\" : a1, \"z2\": z2, \"a2\" : a2, \"z3\" : z3, \"a3\" : a3}\n",
    "\n",
    "    return a3,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_prediction, Y):\n",
    "    # Convert Y_prediction and Y to arrays if they are not already\n",
    "    Y_prediction = cp.array(Y_prediction)\n",
    "    Y = cp.array(Y)\n",
    "\n",
    "    # Calculate the number of examples\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Calculate the number of correctly predicted examples\n",
    "    correct = cp.sum(Y_prediction == Y)\n",
    "\n",
    "    # Calculate the accuracy as a percentage\n",
    "    acc = correct / m * 100\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 759.3029862326139\n",
      "Cost after iteration 100: 110.88356060294558\n",
      "Cost after iteration 200: 110.87669154914134\n",
      "Cost after iteration 300: 110.86973981412262\n",
      "Cost after iteration 400: 110.86267702026187\n",
      "Cost after iteration 500: 110.85547810734775\n",
      "Cost after iteration 600: 110.84811729915387\n",
      "Cost after iteration 700: 110.84056828252666\n",
      "Cost after iteration 800: 110.83280075534077\n",
      "Cost after iteration 900: 110.82478290358875\n",
      "Cost after iteration 1000: 110.8164836837328\n",
      "Cost after iteration 1100: 110.80786482658485\n",
      "Cost after iteration 1200: 110.7988883959909\n",
      "Cost after iteration 1300: 110.78951365417029\n",
      "Cost after iteration 1400: 110.77968780119107\n",
      "Cost after iteration 1500: 110.76935935547147\n",
      "Cost after iteration 1600: 110.75846761293352\n",
      "Cost after iteration 1700: 110.746942339131\n",
      "Cost after iteration 1800: 110.73470978299392\n",
      "Cost after iteration 1900: 110.72168997088822\n",
      "Cost after iteration 2000: 110.70777701301746\n",
      "Cost after iteration 2100: 110.69284750178991\n",
      "Cost after iteration 2200: 110.6767717133397\n",
      "Cost after iteration 2300: 110.65939609010485\n",
      "Cost after iteration 2400: 110.64053724432337\n",
      "Cost after iteration 2500: 110.61998455818454\n",
      "Cost after iteration 2600: 110.59749439592011\n",
      "Cost after iteration 2700: 110.57275030607465\n",
      "Cost after iteration 2800: 110.54537364035775\n",
      "Cost after iteration 2900: 110.51489929928442\n",
      "Cost after iteration 3000: 110.48072220341012\n",
      "Cost after iteration 3100: 110.44210273002321\n",
      "Cost after iteration 3200: 110.39808430749119\n",
      "Cost after iteration 3300: 110.34740822546588\n",
      "Cost after iteration 3400: 110.2884094244909\n",
      "Cost after iteration 3500: 110.21874639212724\n",
      "Cost after iteration 3600: 110.13510670714035\n",
      "Cost after iteration 3700: 110.03263163569758\n",
      "Cost after iteration 3800: 109.90390481095999\n",
      "Cost after iteration 3900: 109.73717103254276\n",
      "Cost after iteration 4000: 109.51270166035843\n",
      "Cost after iteration 4100: 109.19610526336866\n",
      "Cost after iteration 4200: 108.73037858825776\n",
      "Cost after iteration 4300: 108.04966534957416\n",
      "Cost after iteration 4400: 107.1501128226386\n",
      "Cost after iteration 4500: 105.8969786396211\n",
      "Cost after iteration 4600: 103.22391359876045\n",
      "Cost after iteration 4700: nan\n",
      "Cost after iteration 4800: 80.09318655960521\n",
      "Cost after iteration 4900: nan\n",
      "Cost after iteration 5000: nan\n",
      "Cost after iteration 5100: nan\n",
      "Cost after iteration 5200: nan\n",
      "Cost after iteration 5300: nan\n",
      "Cost after iteration 5400: nan\n",
      "Cost after iteration 5500: 103.9525334003963\n",
      "Cost after iteration 5600: nan\n",
      "Cost after iteration 5700: nan\n",
      "Cost after iteration 5800: nan\n",
      "Cost after iteration 5900: nan\n",
      "Cost after iteration 6000: nan\n",
      "Cost after iteration 6100: nan\n",
      "Cost after iteration 6200: nan\n",
      "Cost after iteration 6300: nan\n",
      "Cost after iteration 6400: nan\n",
      "Cost after iteration 6500: nan\n",
      "Cost after iteration 6600: nan\n",
      "Cost after iteration 6700: nan\n",
      "Cost after iteration 6800: nan\n",
      "Cost after iteration 6900: nan\n",
      "Cost after iteration 7000: nan\n",
      "Cost after iteration 7100: nan\n",
      "Cost after iteration 7200: nan\n",
      "Cost after iteration 7300: nan\n",
      "Cost after iteration 7400: nan\n",
      "Cost after iteration 7500: nan\n",
      "Cost after iteration 7600: nan\n",
      "Cost after iteration 7700: nan\n",
      "Cost after iteration 7800: nan\n",
      "Cost after iteration 7900: nan\n",
      "Cost after iteration 8000: nan\n",
      "Cost after iteration 8100: nan\n",
      "Cost after iteration 8200: nan\n",
      "Cost after iteration 8300: nan\n",
      "Cost after iteration 8400: nan\n",
      "Cost after iteration 8500: nan\n",
      "Cost after iteration 8600: nan\n",
      "Cost after iteration 8700: nan\n",
      "Cost after iteration 8800: nan\n",
      "Cost after iteration 8900: nan\n",
      "Cost after iteration 9000: nan\n",
      "Cost after iteration 9100: nan\n",
      "Cost after iteration 9200: nan\n",
      "Cost after iteration 9300: nan\n",
      "Cost after iteration 9400: nan\n",
      "Cost after iteration 9500: nan\n",
      "Cost after iteration 9600: nan\n",
      "Cost after iteration 9700: nan\n",
      "Cost after iteration 9800: nan\n",
      "Cost after iteration 9900: nan\n",
      "\n",
      " Parameters are  {'w1': array([[ 3.58456672e-04,  3.43080485e-04,  1.28392842e-03, ...,\n",
      "        -1.53456528e-03, -8.57362415e-04,  1.87295069e-03],\n",
      "       [-6.88230649e-04, -3.52044012e-04, -1.59247559e-05, ...,\n",
      "         4.22981084e-04, -1.91724344e-03,  1.97509732e-03],\n",
      "       [ 2.69393322e-04, -1.15465319e-03,  2.56464184e-04, ...,\n",
      "        -2.14344244e-03, -1.64235273e-03, -9.89261967e-05],\n",
      "       ...,\n",
      "       [-7.37229497e-04, -2.83136211e-04,  1.82640603e-03, ...,\n",
      "         1.48903621e-04, -1.00350393e-03,  9.59968385e-05],\n",
      "       [-1.67533821e-03, -1.91060471e-03, -7.28465854e-04, ...,\n",
      "        -1.11808222e-05, -3.46716059e-04, -1.73796544e-03],\n",
      "       [ 4.48441420e-04,  1.81871275e-03, -1.00594407e-03, ...,\n",
      "        -9.78570982e-04,  3.70665533e-05, -1.81673132e-03]]), 'w2': array([[-4.91893997e-04,  2.15933060e-03,  4.70759721e-04, ...,\n",
      "         6.21271368e-04,  2.97527951e-04, -5.56305160e-04],\n",
      "       [ 2.78583369e-04, -2.70790330e-05, -4.19728938e-04, ...,\n",
      "        -3.17425269e-04,  2.36091741e-04, -4.19296651e-04],\n",
      "       [ 1.02475438e-03, -1.86749109e-03, -2.61546580e-03, ...,\n",
      "         1.27923434e-05,  1.14876604e-03, -3.52825934e-05],\n",
      "       ...,\n",
      "       [ 8.54473318e-04,  1.01793505e-03,  5.98096688e-04, ...,\n",
      "        -1.65320202e-03,  6.71098108e-04,  1.49548077e-03],\n",
      "       [-3.45818918e-04,  7.76962991e-05,  3.82434004e-04, ...,\n",
      "         7.01543722e-06,  4.99890696e-04, -2.31799741e-03],\n",
      "       [ 4.90340015e-04,  1.10620009e-03,  2.36322407e-04, ...,\n",
      "        -8.25716018e-04,  1.08329448e-03,  1.50360315e-03]]), 'w3': array([[-0.00406246,  0.05356858, -0.00460639, ..., -0.0004056 ,\n",
      "         0.00993154, -0.00501396]]), 'b1': array([[ 2.69753479e-05],\n",
      "       [ 4.36049074e-06],\n",
      "       [-1.50426959e-05],\n",
      "       ...,\n",
      "       [-1.08387758e-04],\n",
      "       [ 7.67087690e-06],\n",
      "       [-2.15120293e-06]]), 'b2': array([[ 6.79852580e-06],\n",
      "       [ 1.24542343e-03],\n",
      "       [ 8.76928117e-06],\n",
      "       ...,\n",
      "       [-7.48075644e-07],\n",
      "       [ 4.63571766e-05],\n",
      "       [ 1.24944337e-05]]), 'b3': array([[-0.81448902]])}\n",
      "Train Accuracy: 100.0\n",
      "Test Accuracy: 55.00000000000001\n"
     ]
    }
   ],
   "source": [
    "X, Y, X_test, Y_test = load_dataset()\n",
    "\n",
    "#Train the model\n",
    "parameters = gradient_descent(X, Y, iterations=4800, learning_rate=0.0005)\n",
    "print(\"\\n Parameters are \",parameters)\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = predict(X, parameters)\n",
    "test_predictions = predict(X_test, parameters)\n",
    "\n",
    "train_accuracy = accuracy(train_predictions, Y)\n",
    "test_accuracy = accuracy(test_predictions, Y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
