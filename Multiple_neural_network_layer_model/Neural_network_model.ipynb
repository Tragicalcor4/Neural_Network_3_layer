{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "import cupy as cp\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from cupy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    assert x_train.shape == (60000, 28, 28)\n",
    "    assert x_test.shape == (10000, 28, 28)\n",
    "    assert y_train.shape == (60000,)\n",
    "    assert y_test.shape == (10000,)\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1).T/255.\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1).T /255.\n",
    "    y_test = y_test.reshape(y_test.shape[-1],1).T\n",
    "    y_train = y_train.reshape(y_train.shape[-1],1).T\n",
    "\n",
    "    x_train = cp.array(x_train)\n",
    "    x_test = cp.array(x_test)\n",
    "    y_train = cp.array(y_train)\n",
    "    y_test = cp.array(y_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_size(X,Y):\n",
    "    \n",
    "    n_x = cp.shape(X)\n",
    "    n_x = n_x[0]\n",
    "    n_h = 5 # size of hidden layer 1\n",
    "    n_z = 4 # size of hidden layer 2\n",
    "    n_y = cp.shape(Y)\n",
    "    n_y = n_y[0]\n",
    "\n",
    "    return n_x,n_h,n_z,n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return cp.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each row of x.\"\"\"\n",
    "    e_x = cp.exp(x - cp.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_z,n_y):\n",
    "\n",
    "    w1 = cp.random.randn(n_h,n_x) * 0.001\n",
    "    b1 = cp.zeros((n_h , 1))\n",
    "    w2 = cp.random.randn(n_z,n_h) * 0.001\n",
    "    b2 = cp.zeros((n_z,1))\n",
    "    w3 = cp.random.randn(n_y,n_z) * 0.001\n",
    "    b3 = cp.zeros((n_y,1))\n",
    "\n",
    "    parameters = { \"w1\" : w1 , \"b1\" : b1 , \"w2\" : w2, \"b2\" : b2, \"w3\" : w3, \"b3\" : b3}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,parameters):\n",
    "\n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    \n",
    "    z1 = cp.dot(w1,X) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = cp.dot(w2,a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = cp.dot(w3,a2) + b3\n",
    "    a3 = relu(z3)\n",
    "\n",
    "    caches = {\"z1\" : z1, \"a1\" : a1, \"z2\": z2, \"a2\" : a2, \"z3\" : z3, \"a3\" : a3}\n",
    "\n",
    "    return a3,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(a3, Y,parameters):\n",
    "    m = Y.shape[0]\n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    epsilon = 1e-7\n",
    "    cost = -1/m * cp.sum(Y*cp.log(a3+epsilon) + (1-Y)*cp.log(1-a3+epsilon)) \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(parameters,caches,X,Y):\n",
    "\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    w1 = parameters[\"w1\"]\n",
    "    w2 = parameters[\"w2\"]\n",
    "    w3 = parameters[\"w3\"]\n",
    "    a1 = caches[\"a1\"]\n",
    "    a2 = caches[\"a2\"]\n",
    "    a3 = caches[\"a3\"]\n",
    "    z1 = caches[\"z1\"]\n",
    "    z2 = caches[\"z2\"]\n",
    "    z3 = caches[\"z3\"]\n",
    "\n",
    "    dz3  = a3 - Y\n",
    "    dw3 = cp.dot(dz3,a2.T)/m \n",
    "    db3 = cp.sum(dz3,axis = 1, keepdims=True)/m\n",
    "    da2 = cp.dot(w3.T,dz3)\n",
    "    dz2 = cp.multiply(da2,a2)\n",
    "    dw2 = cp.dot(dz2,a1.T)/m \n",
    "    db2 = cp.sum(dz2,axis = 1, keepdims=True)/m\n",
    "    da1 = cp.dot(w2.T,dz2)\n",
    "    dz1 = cp.multiply(da1,a1)\n",
    "    dw1 = cp.dot(dz1,X.T)/m \n",
    "    db1 = cp.sum(dz1, axis=1, keepdims= True)/m\n",
    "\n",
    "    backprop = { \"dz3\" : dz3, \"dw3\" : dw3, \"db3\" : db3, \"da2\" : da2, \"dz2\" : dz2, \"dw2\" : dw2, \"db2\" : db2, \"da1\" : da1, \"dz1\" : dz1, \"dw1\" : dw1, \"db1\" : db1}\n",
    "    return backprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(backprop, learning_rate ,parameters):\n",
    "\n",
    "    w1 = copy.deepcopy(parameters[\"w1\"])\n",
    "    w2 = copy.deepcopy(parameters[\"w2\"])\n",
    "    w3 = copy.deepcopy(parameters[\"w3\"])\n",
    "    b1 = copy.deepcopy(parameters[\"b1\"])\n",
    "    b2 = copy.deepcopy(parameters[\"b2\"])\n",
    "    b3 = copy.deepcopy(parameters[\"b3\"])\n",
    "\n",
    "    dw1 = backprop[\"dw1\"]\n",
    "    dw2 = backprop[\"dw2\"]\n",
    "    dw3 = backprop[\"dw3\"]\n",
    "    db1 = backprop[\"db1\"]\n",
    "    db2 = backprop[\"db2\"]\n",
    "    db3 = backprop[\"db3\"]\n",
    "\n",
    "    #updating the parameters\n",
    "\n",
    "    w1 = w1 - (learning_rate * dw1)\n",
    "    w2 = w2 - (learning_rate * dw2)\n",
    "    w3 = w3 - (learning_rate * dw3)\n",
    "\n",
    "    b1 = b1 - (learning_rate * db1)\n",
    "    b2 = b2 - (learning_rate * db2)\n",
    "    b3 = b3 - (learning_rate * db3)\n",
    "\n",
    "    #storing updated parameters in the dictionary\n",
    "\n",
    "    parameters = {\"w1\" : w1, \"w2\": w2, \"w3\" : w3, \"b1\" : b1, \"b2\" : b2, \"b3\" : b3}\n",
    "\n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,iterations,learning_rate):\n",
    "\n",
    "    n_x,n_h,n_z,n_y = layer_size(X,Y)\n",
    "    parameters = initialize_parameters(n_x,n_h,n_z,n_y)\n",
    "\n",
    "    for i in range(0,iterations):\n",
    "        a3,caches = forward_prop(X,parameters)\n",
    "        cost = cost_function(a3,Y,parameters)\n",
    "        backprop = backward_prop(parameters,caches,X,Y)\n",
    "        parameters = update_parameters(backprop, learning_rate ,parameters)\n",
    "\n",
    "        #print(\"updated parameters = \",parameters)\n",
    "        if i % 100 == 0:\n",
    "           print(f\"Cost after iteration {i}: {cost}\")\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    # Implement forward propagation to get predictions\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = cp.zeros((1, m))\n",
    "    A, _ = forward_prop(X, parameters)\n",
    "    Y_prediction = A\n",
    "    return Y_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_prediction, Y):\n",
    "    # Convert Y_prediction and Y to arrays if they are not already\n",
    "    Y_prediction = cp.array(Y_prediction)\n",
    "    Y = cp.array(Y)\n",
    "\n",
    "    # Calculate the number of examples\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Calculate the number of correctly predicted examples\n",
    "    correct = cp.sum(cp.argmax(Y_prediction, axis=0) == cp.argmax(Y, axis=0))\n",
    "\n",
    "    # Calculate the accuracy as a percentage\n",
    "    acc = correct / m * 100\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_test, Y_test = load_dataset()\n",
    "\n",
    "#Train the model\n",
    "parameters = gradient_descent(X, Y, iterations=500, learning_rate=0.001)\n",
    "print(\"\\n Parameters are \",parameters)\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = predict(X, parameters)\n",
    "test_predictions = predict(X_test, parameters)\n",
    "\n",
    "train_accuracy = accuracy(train_predictions, Y)\n",
    "test_accuracy = accuracy(test_predictions, Y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
